{"ast":null,"code":"import { __assign, __awaiter, __extends, __generator } from \"tslib\";\nimport { Credentials, getAmplifyUserAgent } from '@aws-amplify/core';\nimport { Storage } from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport { RekognitionClient, SearchFacesByImageCommand, DetectTextCommand, DetectLabelsCommand, DetectFacesCommand, DetectModerationLabelsCommand, RecognizeCelebritiesCommand } from '@aws-sdk/client-rekognition';\nimport { isStorageSource, isFileSource, isBytesSource, isIdentifyCelebrities, isIdentifyFromCollection } from '../types';\nimport { TextractClient, DetectDocumentTextCommand, AnalyzeDocumentCommand } from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport { categorizeRekognitionBlocks, categorizeTextractBlocks } from './IdentifyTextUtils';\n\nvar AmazonAIIdentifyPredictionsProvider =\n/** @class */\nfunction (_super) {\n  __extends(AmazonAIIdentifyPredictionsProvider, _super);\n\n  function AmazonAIIdentifyPredictionsProvider() {\n    return _super.call(this) || this;\n  }\n\n  AmazonAIIdentifyPredictionsProvider.prototype.getProviderName = function () {\n    return 'AmazonAIIdentifyPredictionsProvider';\n  };\n  /**\n   * Verify user input source and converts it into source object readable by Rekognition and Textract.\n   * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n   * @param {IdentifySource} source - User input source that directs to the object user wants\n   * to identify (storage, file, or bytes).\n   * @return {Promise<Image>} - Promise resolving to the converted source object.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.configureSource = function (source) {\n    return new Promise(function (res, rej) {\n      if (isStorageSource(source)) {\n        var storageConfig = {\n          level: source.level,\n          identityId: source.identityId\n        };\n        Storage.get(source.key, storageConfig).then(function (url) {\n          var parser = /https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n          var parsedURL = url.match(parser);\n          if (parsedURL.length < 3) rej('Invalid S3 key was given.');\n          res({\n            S3Object: {\n              Bucket: parsedURL[1],\n              Name: decodeURIComponent(parsedURL[2])\n            }\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isFileSource(source)) {\n        blobToArrayBuffer(source.file).then(function (buffer) {\n          res({\n            Bytes: new Uint8Array(buffer)\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isBytesSource(source)) {\n        var bytes = source.bytes;\n\n        if (bytes instanceof Blob) {\n          blobToArrayBuffer(bytes).then(function (buffer) {\n            res({\n              Bytes: new Uint8Array(buffer)\n            });\n          }).catch(function (err) {\n            return rej(err);\n          });\n        }\n\n        if (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n          res({\n            Bytes: new Uint8Array(bytes)\n          });\n        } // everything else can be directly passed to Rekognition / Textract.\n\n\n        res({\n          Bytes: bytes\n        });\n      } else {\n        rej('Input source is not configured correctly.');\n      }\n    });\n  };\n  /**\n   * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n   * image and converts it into machine-readable text.\n   * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n   * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyText = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, configFormat, inputDocument, err_1, format, featureTypes, textractParam, rekognitionParam, detectTextCommand, rekognitionData, rekognitionResponse, detectDocumentTextCommand, Blocks, err_2, param, analyzeDocumentCommand, Blocks, err_3;\n\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyText, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).format, configFormat = _e === void 0 ? 'PLAIN' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            this.textractClient = new TextractClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            _f.label = 2;\n\n          case 2:\n            _f.trys.push([2, 4,, 5]);\n\n            return [4\n            /*yield*/\n            , this.configureSource(input.text.source)];\n\n          case 3:\n            inputDocument = _f.sent();\n            return [3\n            /*break*/\n            , 5];\n\n          case 4:\n            err_1 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_1)];\n\n          case 5:\n            format = input.text.format || configFormat;\n            featureTypes = [];\n            if (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n            if (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n            if (!(featureTypes.length === 0)) return [3\n            /*break*/\n            , 11];\n            textractParam = {\n              Document: inputDocument\n            };\n            rekognitionParam = {\n              Image: inputDocument\n            };\n            _f.label = 6;\n\n          case 6:\n            _f.trys.push([6, 9,, 10]);\n\n            detectTextCommand = new DetectTextCommand(rekognitionParam);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectTextCommand)];\n\n          case 7:\n            rekognitionData = _f.sent();\n            rekognitionResponse = categorizeRekognitionBlocks(rekognitionData.TextDetections);\n\n            if (rekognitionResponse.text.words.length < 50) {\n              // did not hit the word limit, return the data\n              return [2\n              /*return*/\n              , rekognitionResponse];\n            }\n\n            detectDocumentTextCommand = new DetectDocumentTextCommand(textractParam);\n            return [4\n            /*yield*/\n            , this.textractClient.send(detectDocumentTextCommand)];\n\n          case 8:\n            Blocks = _f.sent().Blocks;\n\n            if (rekognitionData.TextDetections.length > Blocks.length) {\n              return [2\n              /*return*/\n              , rekognitionResponse];\n            }\n\n            return [2\n            /*return*/\n            , categorizeTextractBlocks(Blocks)];\n\n          case 9:\n            err_2 = _f.sent();\n            Promise.reject(err_2);\n            return [3\n            /*break*/\n            , 10];\n\n          case 10:\n            return [3\n            /*break*/\n            , 15];\n\n          case 11:\n            param = {\n              Document: inputDocument,\n              FeatureTypes: featureTypes\n            };\n            _f.label = 12;\n\n          case 12:\n            _f.trys.push([12, 14,, 15]);\n\n            analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n            return [4\n            /*yield*/\n            , this.textractClient.send(analyzeDocumentCommand)];\n\n          case 13:\n            Blocks = _f.sent().Blocks;\n            return [2\n            /*return*/\n            , categorizeTextractBlocks(Blocks)];\n\n          case 14:\n            err_3 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_3)];\n\n          case 15:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Identify instances of real world entities from an image and if it contains unsafe content.\n   * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyLabels = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, type, inputImage_1, param, servicePromises, entityType, err_4;\n\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            _f.trys.push([0, 3,, 4]);\n\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyLabels, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).type, type = _e === void 0 ? 'LABELS' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            return [4\n            /*yield*/\n            , this.configureSource(input.labels.source).then(function (data) {\n              inputImage_1 = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 2:\n            _f.sent();\n\n            param = {\n              Image: inputImage_1\n            };\n            servicePromises = [];\n            entityType = input.labels.type || type;\n\n            if (entityType === 'LABELS' || entityType === 'ALL') {\n              servicePromises.push(this.detectLabels(param));\n            }\n\n            if (entityType === 'UNSAFE' || entityType === 'ALL') {\n              servicePromises.push(this.detectModerationLabels(param));\n            }\n\n            return [2\n            /*return*/\n            , Promise.all(servicePromises).then(function (data) {\n              var identifyResult = {}; // concatenate resolved promises to a single object\n\n              data.forEach(function (val) {\n                identifyResult = __assign(__assign({}, identifyResult), val);\n              });\n              return identifyResult;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 3:\n            err_4 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_4)];\n\n          case 4:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectLabels and organizes the returned data.\n   * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.detectLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectLabelsCommand, data, detectLabelData, err_5;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n\n            detectLabelsCommand = new DetectLabelsCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectLabelsCommand)];\n\n          case 1:\n            data = _a.sent();\n            if (!data.Labels) return [2\n            /*return*/\n            , {\n              labels: null\n            }]; // no image was detected\n\n            detectLabelData = data.Labels.map(function (val) {\n              var boxes = val.Instances ? val.Instances.map(function (val) {\n                return makeCamelCase(val.BoundingBox);\n              }) : undefined;\n              return {\n                name: val.Name,\n                boundingBoxes: boxes,\n                metadata: {\n                  confidence: val.Confidence,\n                  parents: makeCamelCaseArray(val.Parents)\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              labels: detectLabelData\n            }];\n\n          case 2:\n            err_5 = _a.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_5)];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectModerationLabels and organizes the returned data.\n   * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.detectModerationLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectModerationLabelsCommand, data, err_6;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n\n            detectModerationLabelsCommand = new DetectModerationLabelsCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectModerationLabelsCommand)];\n\n          case 1:\n            data = _a.sent();\n\n            if (data.ModerationLabels.length !== 0) {\n              return [2\n              /*return*/\n              , {\n                unsafe: 'YES'\n              }];\n            } else {\n              return [2\n              /*return*/\n              , {\n                unsafe: 'NO'\n              }];\n            }\n\n            return [3\n            /*break*/\n            , 3];\n\n          case 2:\n            err_6 = _a.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_6)];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Identify faces within an image that is provided as input, and match faces from a collection\n   * or identify celebrities.\n   * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n   * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyEntities = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, celebrityDetectionEnabled, _e, _f, _g, collectionIdConfig, _h, maxFacesConfig, inputImage, param, recognizeCelebritiesCommand, data, faces, err_7, _j, _k, collectionId, _l, maxFaces, updatedParam, searchFacesByImageCommand, data, faces, err_8, detectFacesCommand, data, faces, err_9;\n\n      var _this = this;\n\n      return __generator(this, function (_m) {\n        switch (_m.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _m.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyEntities, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.celebrityDetectionEnabled, celebrityDetectionEnabled = _d === void 0 ? false : _d, _e = _b.defaults, _f = _e === void 0 ? {} : _e, _g = _f.collectionId, collectionIdConfig = _g === void 0 ? '' : _g, _h = _f.maxEntities, maxFacesConfig = _h === void 0 ? 50 : _h; // default arguments\n\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            return [4\n            /*yield*/\n            , this.configureSource(input.entities.source).then(function (data) {\n              return inputImage = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 2:\n            _m.sent();\n\n            param = {\n              Attributes: ['ALL'],\n              Image: inputImage\n            };\n            if (!(isIdentifyCelebrities(input.entities) && input.entities.celebrityDetection)) return [3\n            /*break*/\n            , 7];\n\n            if (!celebrityDetectionEnabled) {\n              return [2\n              /*return*/\n              , Promise.reject('Error: You have to enable celebrity detection first')];\n            }\n\n            _m.label = 3;\n\n          case 3:\n            _m.trys.push([3, 5,, 6]);\n\n            recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(recognizeCelebritiesCommand)];\n\n          case 4:\n            data = _m.sent();\n            faces = data.CelebrityFaces.map(function (celebrity) {\n              return {\n                boundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n                landmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n                metadata: __assign(__assign({}, makeCamelCase(celebrity, ['Id', 'Name', 'Urls'])), {\n                  pose: makeCamelCase(celebrity.Face.Pose)\n                })\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 5:\n            err_7 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_7)];\n\n          case 6:\n            return [3\n            /*break*/\n            , 15];\n\n          case 7:\n            if (!(isIdentifyFromCollection(input.entities) && input.entities.collection)) return [3\n            /*break*/\n            , 12];\n            _j = input.entities, _k = _j.collectionId, collectionId = _k === void 0 ? collectionIdConfig : _k, _l = _j.maxEntities, maxFaces = _l === void 0 ? maxFacesConfig : _l;\n            updatedParam = __assign(__assign({}, param), {\n              CollectionId: collectionId,\n              MaxFaces: maxFaces\n            });\n            _m.label = 8;\n\n          case 8:\n            _m.trys.push([8, 10,, 11]);\n\n            searchFacesByImageCommand = new SearchFacesByImageCommand(updatedParam);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(searchFacesByImageCommand)];\n\n          case 9:\n            data = _m.sent();\n            faces = data.FaceMatches.map(function (val) {\n              return {\n                boundingBox: makeCamelCase(val.Face.BoundingBox),\n                metadata: {\n                  externalImageId: _this.decodeExternalImageId(val.Face.ExternalImageId),\n                  similarity: val.Similarity\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 10:\n            err_8 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_8)];\n\n          case 11:\n            return [3\n            /*break*/\n            , 15];\n\n          case 12:\n            _m.trys.push([12, 14,, 15]);\n\n            detectFacesCommand = new DetectFacesCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectFacesCommand)];\n\n          case 13:\n            data = _m.sent();\n            faces = data.FaceDetails.map(function (detail) {\n              // face attributes keys we want to extract from Rekognition's response\n              var attributeKeys = ['Smile', 'Eyeglasses', 'Sunglasses', 'Gender', 'Beard', 'Mustache', 'EyesOpen', 'MouthOpen'];\n              var faceAttributes = makeCamelCase(detail, attributeKeys);\n\n              if (detail.Emotions) {\n                faceAttributes['emotions'] = detail.Emotions.map(function (emotion) {\n                  return emotion.Type;\n                });\n              }\n\n              return {\n                boundingBox: makeCamelCase(detail.BoundingBox),\n                landmarks: makeCamelCaseArray(detail.Landmarks),\n                ageRange: makeCamelCase(detail.AgeRange),\n                attributes: faceAttributes,\n                metadata: {\n                  confidence: detail.Confidence,\n                  pose: makeCamelCase(detail.Pose)\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 14:\n            err_9 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_9)];\n\n          case 15:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  AmazonAIIdentifyPredictionsProvider.prototype.decodeExternalImageId = function (externalImageId) {\n    return ('' + externalImageId).replace(/::/g, '/');\n  };\n\n  return AmazonAIIdentifyPredictionsProvider;\n}(AbstractIdentifyPredictionsProvider);\n\nexport { AmazonAIIdentifyPredictionsProvider };","map":{"version":3,"mappings":";AAAA,SACCA,WADD,EAGCC,mBAHD,QAIO,mBAJP;AAKA,SAASC,OAAT,QAAwB,sBAAxB;AACA,SAASC,mCAAT,QAAoD,oBAApD;AACA,SACCC,iBADD,EAECC,yBAFD,EAGCC,iBAHD,EAKCC,mBALD,EAOCC,kBAPD,EAQCC,6BARD,EAUCC,2BAVD,QAWO,6BAXP;AAYA,SAMCC,eAND,EAOCC,YAPD,EAQCC,aARD,EAWCC,qBAXD,EAYCC,wBAZD,QAeO,UAfP;AAsBA,SACCC,cADD,EAECC,yBAFD,EAICC,sBAJD,QAMO,0BANP;AAOA,SAASC,aAAT,EAAwBC,kBAAxB,EAA4CC,iBAA5C,QAAqE,SAArE;AACA,SACCC,2BADD,EAECC,wBAFD,QAGO,qBAHP;;AAKA;AAAA;AAAA;AAAyDC;;AAIxD;WACCC,qBAAO;AACP;;AAEDC;AACC,WAAO,qCAAP;AACA,GAFD;AAIA;;;;;;;;;AAOQA,kEAAR,UAAwBC,MAAxB,EAA8C;AAC7C,WAAO,IAAIC,OAAJ,CAAY,UAACC,GAAD,EAAMC,GAAN,EAAS;AAC3B,UAAInB,eAAe,CAACgB,MAAD,CAAnB,EAA6B;AAC5B,YAAMI,aAAa,GAAG;AACrBC,eAAK,EAAEL,MAAM,CAACK,KADO;AAErBC,oBAAU,EAAEN,MAAM,CAACM;AAFE,SAAtB;AAIA/B,eAAO,CAACgC,GAAR,CAAYP,MAAM,CAACQ,GAAnB,EAAwBJ,aAAxB,EACEK,IADF,CACO,UAACC,GAAD,EAAY;AACjB,cAAMC,MAAM,GACX,6EADD;AAEA,cAAMC,SAAS,GAAGF,GAAG,CAACG,KAAJ,CAAUF,MAAV,CAAlB;AACA,cAAIC,SAAS,CAACE,MAAV,GAAmB,CAAvB,EAA0BX,GAAG,CAAC,2BAAD,CAAH;AAC1BD,aAAG,CAAC;AACHa,oBAAQ,EAAE;AACTC,oBAAM,EAAEJ,SAAS,CAAC,CAAD,CADR;AAETK,kBAAI,EAAEC,kBAAkB,CAACN,SAAS,CAAC,CAAD,CAAV;AAFf;AADP,WAAD,CAAH;AAMA,SAZF,EAaEO,KAbF,CAaQ,eAAG;AAAI,oBAAG,CAACC,GAAD,CAAH;AAAQ,SAbvB;AAcA,OAnBD,MAmBO,IAAInC,YAAY,CAACe,MAAD,CAAhB,EAA0B;AAChCN,yBAAiB,CAACM,MAAM,CAACqB,IAAR,CAAjB,CACEZ,IADF,CACO,kBAAM;AACXP,aAAG,CAAC;AAAEoB,iBAAK,EAAE,IAAIC,UAAJ,CAAeC,MAAf;AAAT,WAAD,CAAH;AACA,SAHF,EAIEL,KAJF,CAIQ,eAAG;AAAI,oBAAG,CAACC,GAAD,CAAH;AAAQ,SAJvB;AAKA,OANM,MAMA,IAAIlC,aAAa,CAACc,MAAD,CAAjB,EAA2B;AACjC,YAAMyB,KAAK,GAAGzB,MAAM,CAACyB,KAArB;;AACA,YAAIA,KAAK,YAAYC,IAArB,EAA2B;AAC1BhC,2BAAiB,CAAC+B,KAAD,CAAjB,CACEhB,IADF,CACO,kBAAM;AACXP,eAAG,CAAC;AAAEoB,mBAAK,EAAE,IAAIC,UAAJ,CAAeC,MAAf;AAAT,aAAD,CAAH;AACA,WAHF,EAIEL,KAJF,CAIQ,eAAG;AAAI,sBAAG,CAACC,GAAD,CAAH;AAAQ,WAJvB;AAKA;;AACD,YAAIK,KAAK,YAAYE,WAAjB,IAAgCF,KAAK,YAAYG,MAArD,EAA6D;AAC5D1B,aAAG,CAAC;AAAEoB,iBAAK,EAAE,IAAIC,UAAJ,CAAeE,KAAf;AAAT,WAAD,CAAH;AACA,SAXgC,CAYjC;;;AACAvB,WAAG,CAAC;AAAEoB,eAAK,EAAEG;AAAT,SAAD,CAAH;AACA,OAdM,MAcA;AACNtB,WAAG,CAAC,2CAAD,CAAH;AACA;AACD,KA3CM,CAAP;AA4CA,GA7CO;AA+CR;;;;;;;;AAMgBJ,+DAAhB,UACC8B,KADD,EACyB;;;;;;;AAEJ;AAAA;AAAA,cAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;AAAduB,uBAAW,GAAGC,SAAd;AACN,gBAAI,CAACD,WAAL,EAAkB;AAAA;AAAA,cAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;AAEjBC,iBAIG,KAAKC,OAAL,CAAYC,YAJf,uBAGI,EAHJ,GAGMF,EAHN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,gBAFD,EAEaC,sBAAmC,EAAnC,GAAqCD,EAArC,EAAqCE,MAFlD,EAEqBC,YAAY,mBAAG,OAAH,GAAUF,EAF3C;AAKD,iBAAKG,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;AAC9C4D,oBAAM,QADwC;AAE9CP,yBAAW,aAFmC;AAG9Ca,6BAAe,EAAErE,mBAAmB;AAHU,aAAtB,CAAzB;AAKA,iBAAKsE,cAAL,GAAsB,IAAIvD,cAAJ,CAAmB;AACxCgD,oBAAM,QADkC;AAExCP,yBAAW,aAF6B;AAGxCa,6BAAe,EAAErE,mBAAmB;AAHI,aAAnB,CAAtB;;;;;;AAQiB;AAAA;AAAA,cAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACiB,IAAN,CAAW9C,MAAhC,CAAN;;;AAAhB+C,yBAAa,GAAGhB,SAAhB;;;;;;;AAEA;AAAA;AAAA,cAAO9B,OAAO,CAAC+B,MAAR,CAAegB,KAAf,CAAP;;;AAIKR,kBAAM,GAAGX,KAAK,CAACiB,IAAN,CAAWN,MAAX,IAAqBC,YAA9B;AACAQ,wBAAY,GAAiB,EAA7B;AACN,gBAAIT,MAAM,KAAK,MAAX,IAAqBA,MAAM,KAAK,KAApC,EAA2CS,YAAY,CAACC,IAAb,CAAkB,OAAlB;AAC3C,gBAAIV,MAAM,KAAK,OAAX,IAAsBA,MAAM,KAAK,KAArC,EAA4CS,YAAY,CAACC,IAAb,CAAkB,QAAlB;kBAExCD,YAAY,CAACnC,MAAb,KAAwB,IAAxB;AAAA;AAAA;AAMGqC,yBAAa,GAAmC;AACrDC,sBAAQ,EAAEL;AAD2C,aAAhD;AAGAM,4BAAgB,GAA2B;AAChDC,mBAAK,EAAEP;AADyC,aAA3C;;;;;;AAKCQ,6BAAiB,GAAG,IAAI5E,iBAAJ,CAAsB0E,gBAAtB,CAApB;AACkB;AAAA;AAAA,cAAM,KAAKX,iBAAL,CAAuBc,IAAvB,CAC7BD,iBAD6B,CAAN;;;AAAlBE,2BAAe,GAAG1B,SAAlB;AAIA2B,+BAAmB,GAAG/D,2BAA2B,CACtD8D,eAAe,CAACE,cADsC,CAAjD;;AAGN,gBAAID,mBAAmB,CAACZ,IAApB,CAAyBc,KAAzB,CAA+B9C,MAA/B,GAAwC,EAA5C,EAAgD;AAC/C;AACA;AAAA;AAAA,gBAAO4C,mBAAP;AACA;;AAEKG,qCAAyB,GAAG,IAAIvE,yBAAJ,CACjC6D,aADiC,CAA5B;AAIa;AAAA;AAAA,cAAM,KAAKP,cAAL,CAAoBY,IAApB,CACxBK,yBADwB,CAAN;;;AAAXC,kBAAM,GAAK/B,UAElB+B,MAFO;;AAIR,gBAAIL,eAAe,CAACE,cAAhB,CAA+B7C,MAA/B,GAAwCgD,MAAM,CAAChD,MAAnD,EAA2D;AAC1D;AAAA;AAAA,gBAAO4C,mBAAP;AACA;;AAED;AAAA;AAAA,cAAO9D,wBAAwB,CAACkE,MAAD,CAA/B;;;;AAEA7D,mBAAO,CAAC+B,MAAR,CAAe+B,KAAf;;;;;;;;;;;AAGKC,iBAAK,GAAgC;AAC1CZ,sBAAQ,EAAEL,aADgC;AAE1CkB,0BAAY,EAAEhB;AAF4B,aAArC;;;;;;AAMCiB,kCAAsB,GAAG,IAAI3E,sBAAJ,CAA2ByE,KAA3B,CAAzB;AACa;AAAA;AAAA,cAAM,KAAKpB,cAAL,CAAoBY,IAApB,CACxBU,sBADwB,CAAN;;;AAAXJ,kBAAM,GAAK/B,UAElB+B,MAFO;AAGR;AAAA;AAAA,cAAOlE,wBAAwB,CAACkE,MAAD,CAA/B;;;;AAEA;AAAA;AAAA,cAAO7D,OAAO,CAAC+B,MAAR,CAAemC,KAAf,CAAP;;;;;;;;;AAGF,GA9Fe;AAgGhB;;;;;;;AAKgBpE,iEAAhB,UACC8B,KADD,EAC2B;;;;;;;;;AAGL;AAAA;AAAA,cAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;AAAduB,uBAAW,GAAGC,SAAd;AACN,gBAAI,CAACD,WAAL,EAAkB;AAAA;AAAA,cAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;AAEjBC,iBAIG,KAAKC,OAAL,CAAYkC,cAJf,uBAGI,EAHJ,GAGMnC,EAHN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,gBAFD,EAEaC,sBAAoB,EAApB,GAAsBD,EAAtB,EAAsB+B,IAFnC,EAEaA,IAAI,mBAAG,QAAH,GAAW9B,EAF5B;AAKD,iBAAKG,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;AAC9C4D,oBAAM,QADwC;AAE9CP,yBAAW,aAFmC;AAG9Ca,6BAAe,EAAErE,mBAAmB;AAHU,aAAtB,CAAzB;AAMA;AAAA;AAAA,cAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACyC,MAAN,CAAatE,MAAlC,EACJS,IADI,CACC,gBAAI;AACT8D,0BAAU,GAAGC,IAAb;AACA,aAHI,EAIJrD,KAJI,CAIE,eAAG;AACT,qBAAOlB,OAAO,CAAC+B,MAAR,CAAeZ,GAAf,CAAP;AACA,aANI,CAAN;;;AAAAW;;AAOMiC,iBAAK,GAAG;AAAEV,mBAAK,EAAEiB;AAAT,aAAR;AACAE,2BAAe,GAAG,EAAlB;AAGAC,sBAAU,GAAG7C,KAAK,CAACyC,MAAN,CAAaD,IAAb,IAAqBA,IAAlC;;AACN,gBAAIK,UAAU,KAAK,QAAf,IAA2BA,UAAU,KAAK,KAA9C,EAAqD;AACpDD,6BAAe,CAACvB,IAAhB,CAAqB,KAAKyB,YAAL,CAAkBX,KAAlB,CAArB;AACA;;AACD,gBAAIU,UAAU,KAAK,QAAf,IAA2BA,UAAU,KAAK,KAA9C,EAAqD;AACpDD,6BAAe,CAACvB,IAAhB,CAAqB,KAAK0B,sBAAL,CAA4BZ,KAA5B,CAArB;AACA;;AAED;AAAA;AAAA,cAAO/D,OAAO,CAAC4E,GAAR,CAAYJ,eAAZ,EACLhE,IADK,CACA,gBAAI;AACT,kBAAIqE,cAAc,GAAyB,EAA3C,CADS,CAET;;AACAN,kBAAI,CAACO,OAAL,CAAa,eAAG;AACfD,8BAAc,yBAAQA,cAAR,GAA2BE,GAA3B,CAAd;AACA,eAFD;AAGA,qBAAOF,cAAP;AACA,aARK,EASL3D,KATK,CASC,eAAG;AAAI,4BAAO,CAACa,MAAR,CAAeZ,GAAf;AAAmB,aAT3B,CAAP;;;;AAWA;AAAA;AAAA,cAAOnB,OAAO,CAAC+B,MAAR,CAAeiD,KAAf,CAAP;;;;;;;;;AAED,GAlDe;AAoDhB;;;;;;;AAKclF,+DAAd,UACCiE,KADD,EACgC;;;;;;;;AAGxBkB,+BAAmB,GAAG,IAAItG,mBAAJ,CAAwBoF,KAAxB,CAAtB;AACO;AAAA;AAAA,cAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAA4B0B,mBAA5B,CAAN;;;AAAPV,gBAAI,GAAGvC,SAAP;AACN,gBAAI,CAACuC,IAAI,CAACW,MAAV,EAAkB;AAAA;AAAA,cAAO;AAAEb,oBAAM,EAAE;AAAV,aAAP,GAAyB;;AACrCc,2BAAe,GAAGZ,IAAI,CAACW,MAAL,CAAYE,GAAZ,CAAgB,eAAG;AAC1C,kBAAMC,KAAK,GAAGN,GAAG,CAACO,SAAJ,GACXP,GAAG,CAACO,SAAJ,CAAcF,GAAd,CAAkB,eAAG;AAAI,oCAAa,CAACL,GAAG,CAACQ,WAAL,CAAb;AAA8B,eAAvD,CADW,GAEXC,SAFH;AAGA,qBAAO;AACNC,oBAAI,EAAEV,GAAG,CAAC/D,IADJ;AAEN0E,6BAAa,EAAEL,KAFT;AAGNM,wBAAQ,EAAE;AACTC,4BAAU,EAAEb,GAAG,CAACc,UADP;AAETC,yBAAO,EAAEtG,kBAAkB,CAACuF,GAAG,CAACgB,OAAL;AAFlB;AAHJ,eAAP;AAQA,aAZuB,CAAlB;AAaN;AAAA;AAAA,cAAO;AAAE1B,oBAAM,EAAEc;AAAV,aAAP;;;;AAEA;AAAA;AAAA,cAAOnF,OAAO,CAAC+B,MAAR,CAAeiE,KAAf,CAAP;;;;;;;;;AAED,GAxBa;AA0Bd;;;;;;;AAKclG,yEAAd,UACCiE,KADD,EAC0C;;;;;;;;AAGlCkC,yCAA6B,GAAG,IAAIpH,6BAAJ,CACrCkF,KADqC,CAAhC;AAGO;AAAA;AAAA,cAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAClB0C,6BADkB,CAAN;;;AAAP1B,gBAAI,GAAGvC,SAAP;;AAGN,gBAAIuC,IAAI,CAAC2B,gBAAL,CAAsBrF,MAAtB,KAAiC,CAArC,EAAwC;AACvC;AAAA;AAAA,gBAAO;AAAEsF,sBAAM,EAAE;AAAV,eAAP;AACA,aAFD,MAEO;AACN;AAAA;AAAA,gBAAO;AAAEA,sBAAM,EAAE;AAAV,eAAP;AACA;;;;;;;;AAED;AAAA;AAAA,cAAOnG,OAAO,CAAC+B,MAAR,CAAeqE,KAAf,CAAP;;;;;;;;;AAED,GAlBa;AAoBd;;;;;;;;AAMgBtG,mEAAhB,UACC8B,KADD,EAC6B;;;;;;;;;AAER;AAAA;AAAA,cAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;AAAduB,uBAAW,GAAGwE,SAAd;AACN,gBAAI,CAACxE,WAAL,EAAkB;AAAA;AAAA,cAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;AAEjBC,iBAQG,KAAKC,OAAL,CAAYqE,gBARf,uBAOI,EAPJ,GAOMtE,EAPN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,iCAFD,EAECkE,yBAAyB,mBAAG,KAAH,GAAQlE,EAFlC,EAGCC,gBAHD,EAGCR,qBAGI,EAHJ,GAGMQ,EANP,EAIEkE,oBAJF,EAIgBC,kBAAkB,mBAAG,EAAH,GAAKD,EAJvC,EAKEE,mBALF,EAKeC,cAAc,mBAAG,EAAH,GAAKD,EALlC,EASD;;AAEA,iBAAKjE,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;AAC9C4D,oBAAM,QADwC;AAE9CP,yBAAW,aAFmC;AAG9Ca,6BAAe,EAAErE,mBAAmB;AAHU,aAAtB,CAAzB;AAMA;AAAA;AAAA,cAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACgF,QAAN,CAAe7G,MAApC,EACJS,IADI,CACC,gBAAI;AAAI,qBAACqG,UAAU,GAAGtC,IAAd;AAAmB,aAD5B,EAEJrD,KAFI,CAEE,eAAG;AACT,qBAAOlB,OAAO,CAAC+B,MAAR,CAAeZ,GAAf,CAAP;AACA,aAJI,CAAN;;;AAAAkF;;AAMMtC,iBAAK,GAAG;AAAE+C,wBAAU,EAAE,CAAC,KAAD,CAAd;AAAuBzD,mBAAK,EAAEwD;AAA9B,aAAR;kBAGL3H,qBAAqB,CAAC0C,KAAK,CAACgF,QAAP,CAArB,IACAhF,KAAK,CAACgF,QAAN,CAAeG,qBADf;AAAA;AAAA;;AAGA,gBAAI,CAACR,yBAAL,EAAgC;AAC/B;AAAA;AAAA,gBAAOvG,OAAO,CAAC+B,MAAR,CACN,qDADM,CAAP;AAGA;;;;;;;AAEMiF,uCAA2B,GAAG,IAAIlI,2BAAJ,CACnCiF,KADmC,CAA9B;AAGO;AAAA;AAAA,cAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAClByD,2BADkB,CAAN;;;AAAPzC,gBAAI,GAAG8B,SAAP;AAGAY,iBAAK,GAAG1C,IAAI,CAAC2C,cAAL,CAAoB9B,GAApB,CAAwB,qBAAS;AAC9C,qBAAO;AACN+B,2BAAW,EAAE5H,aAAa,CAAC6H,SAAS,CAACC,IAAV,CAAe9B,WAAhB,CADpB;AAEN+B,yBAAS,EAAE9H,kBAAkB,CAAC4H,SAAS,CAACC,IAAV,CAAeE,SAAhB,CAFvB;AAGN5B,wBAAQ,wBACJpG,aAAa,CAAC6H,SAAD,EAAY,CAAC,IAAD,EAAO,MAAP,EAAe,MAAf,CAAZ,CADT,GAC4C;AACnDI,sBAAI,EAAEjI,aAAa,CAAC6H,SAAS,CAACC,IAAV,CAAeI,IAAhB;AADgC,iBAD5C;AAHF,eAAP;AAQA,aATa,CAAR;AAUN;AAAA;AAAA,cAAO;AAAEb,sBAAQ,EAAEK;AAAZ,aAAP;;;;AAEA;AAAA;AAAA,cAAOjH,OAAO,CAAC+B,MAAR,CAAe2F,KAAf,CAAP;;;;;;;;kBAGDvI,wBAAwB,CAACyC,KAAK,CAACgF,QAAP,CAAxB,IACAhF,KAAK,CAACgF,QAAN,CAAee,aADf;AAAA;AAAA;AAGMC,iBAGFhG,KAAK,CAACgF,QAHJ,EACLiB,oBADK,EACLC,YAAY,mBAAGrB,kBAAH,GAAqBoB,EAD5B,EAELE,mBAFK,EAEQC,QAAQ,mBAAGrB,cAAH,GAAiBoB,EAFjC;AAKAE,wBAAY,yBACdlE,KADc,GACT;AACRmE,0BAAY,EAAEJ,YADN;AAERK,sBAAQ,EAAEH;AAFF,aADS,CAAZ;;;;;;AAMCI,qCAAyB,GAAG,IAAI3J,yBAAJ,CACjCwJ,YADiC,CAA5B;AAGO;AAAA;AAAA,cAAM,KAAKxF,iBAAL,CAAuBc,IAAvB,CAClB6E,yBADkB,CAAN;;;AAAP7D,gBAAI,GAAG8B,SAAP;AAGAY,iBAAK,GAAG1C,IAAI,CAAC8D,WAAL,CAAiBjD,GAAjB,CAAqB,eAAG;AACrC,qBAAO;AACN+B,2BAAW,EAAE5H,aAAa,CAACwF,GAAG,CAACsC,IAAJ,CAAS9B,WAAV,CADpB;AAENI,wBAAQ,EAAE;AACT2C,iCAAe,EAAEC,KAAI,CAACC,qBAAL,CAChBzD,GAAG,CAACsC,IAAJ,CAASoB,eADO,CADR;AAITC,4BAAU,EAAE3D,GAAG,CAAC4D;AAJP;AAFJ,eAAP;AASA,aAVa,CAAR;AAWN;AAAA;AAAA,cAAO;AAAE/B,sBAAQ,EAAEK;AAAZ,aAAP;;;;AAEA;AAAA;AAAA,cAAOjH,OAAO,CAAC+B,MAAR,CAAe6G,KAAf,CAAP;;;;;;;;;;AAIMC,8BAAkB,GAAG,IAAIjK,kBAAJ,CAAuBmF,KAAvB,CAArB;AACO;AAAA;AAAA,cAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAA4BsF,kBAA5B,CAAN;;;AAAPtE,gBAAI,GAAG8B,SAAP;AACAY,iBAAK,GAAG1C,IAAI,CAACuE,WAAL,CAAiB1D,GAAjB,CAAqB,kBAAM;AACxC;AACA,kBAAM2D,aAAa,GAAG,CACrB,OADqB,EAErB,YAFqB,EAGrB,YAHqB,EAIrB,QAJqB,EAKrB,OALqB,EAMrB,UANqB,EAOrB,UAPqB,EAQrB,WARqB,CAAtB;AAUA,kBAAMC,cAAc,GAAGzJ,aAAa,CAAC0J,MAAD,EAASF,aAAT,CAApC;;AACA,kBAAIE,MAAM,CAACC,QAAX,EAAqB;AACpBF,8BAAc,CAAC,UAAD,CAAd,GAA6BC,MAAM,CAACC,QAAP,CAAgB9D,GAAhB,CAC5B,mBAAO;AAAI,gCAAO,CAAC+D,IAAR;AAAY,iBADK,CAA7B;AAGA;;AACD,qBAAO;AACNhC,2BAAW,EAAE5H,aAAa,CAAC0J,MAAM,CAAC1D,WAAR,CADpB;AAEN+B,yBAAS,EAAE9H,kBAAkB,CAACyJ,MAAM,CAAC1B,SAAR,CAFvB;AAGN6B,wBAAQ,EAAE7J,aAAa,CAAC0J,MAAM,CAACI,QAAR,CAHjB;AAINC,0BAAU,EAAEN,cAJN;AAKNrD,wBAAQ,EAAE;AACTC,4BAAU,EAAEqD,MAAM,CAACpD,UADV;AAET2B,sBAAI,EAAEjI,aAAa,CAAC0J,MAAM,CAACxB,IAAR;AAFV;AALJ,eAAP;AAUA,aA5Ba,CAAR;AA6BN;AAAA;AAAA,cAAO;AAAEb,sBAAQ,EAAEK;AAAZ,aAAP;;;;AAEA;AAAA;AAAA,cAAOjH,OAAO,CAAC+B,MAAR,CAAewH,KAAf,CAAP;;;;;;;;;AAGF,GAvIe;;AAyIRzJ,wEAAR,UAA8BwI,eAA9B,EAAqD;AACpD,WAAO,CAAC,KAAKA,eAAN,EAAuBkB,OAAvB,CAA+B,KAA/B,EAAsC,GAAtC,CAAP;AACA,GAFO;;AAGT;AAAC,CA3aD,CAAyDjL,mCAAzD","names":["Credentials","getAmplifyUserAgent","Storage","AbstractIdentifyPredictionsProvider","RekognitionClient","SearchFacesByImageCommand","DetectTextCommand","DetectLabelsCommand","DetectFacesCommand","DetectModerationLabelsCommand","RecognizeCelebritiesCommand","isStorageSource","isFileSource","isBytesSource","isIdentifyCelebrities","isIdentifyFromCollection","TextractClient","DetectDocumentTextCommand","AnalyzeDocumentCommand","makeCamelCase","makeCamelCaseArray","blobToArrayBuffer","categorizeRekognitionBlocks","categorizeTextractBlocks","__extends","_super","AmazonAIIdentifyPredictionsProvider","source","Promise","res","rej","storageConfig","level","identityId","get","key","then","url","parser","parsedURL","match","length","S3Object","Bucket","Name","decodeURIComponent","catch","err","file","Bytes","Uint8Array","buffer","bytes","Blob","ArrayBuffer","Buffer","input","credentials","_f","reject","_a","_config","identifyText","_c","region","_d","_e","format","configFormat","rekognitionClient","customUserAgent","textractClient","configureSource","text","inputDocument","err_1","featureTypes","push","textractParam","Document","rekognitionParam","Image","detectTextCommand","send","rekognitionData","rekognitionResponse","TextDetections","words","detectDocumentTextCommand","Blocks","err_2","param","FeatureTypes","analyzeDocumentCommand","err_3","identifyLabels","type","labels","inputImage_1","data","servicePromises","entityType","detectLabels","detectModerationLabels","all","identifyResult","forEach","val","err_4","detectLabelsCommand","Labels","detectLabelData","map","boxes","Instances","BoundingBox","undefined","name","boundingBoxes","metadata","confidence","Confidence","parents","Parents","err_5","detectModerationLabelsCommand","ModerationLabels","unsafe","err_6","_m","identifyEntities","celebrityDetectionEnabled","_g","collectionIdConfig","_h","maxFacesConfig","entities","inputImage","Attributes","celebrityDetection","recognizeCelebritiesCommand","faces","CelebrityFaces","boundingBox","celebrity","Face","landmarks","Landmarks","pose","Pose","err_7","collection","_j","_k","collectionId","_l","maxFaces","updatedParam","CollectionId","MaxFaces","searchFacesByImageCommand","FaceMatches","externalImageId","_this","decodeExternalImageId","ExternalImageId","similarity","Similarity","err_8","detectFacesCommand","FaceDetails","attributeKeys","faceAttributes","detail","Emotions","Type","ageRange","AgeRange","attributes","err_9","replace"],"sources":["/home/dalienst/node_modules/@aws-amplify/predictions/src/Providers/AmazonAIIdentifyPredictionsProvider.ts"],"sourcesContent":["import {\n\tCredentials,\n\tConsoleLogger as Logger,\n\tgetAmplifyUserAgent,\n} from '@aws-amplify/core';\nimport { Storage } from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport {\n\tRekognitionClient,\n\tSearchFacesByImageCommand,\n\tDetectTextCommand,\n\tDetectTextCommandInput,\n\tDetectLabelsCommand,\n\tDetectLabelsCommandInput,\n\tDetectFacesCommand,\n\tDetectModerationLabelsCommand,\n\tDetectModerationLabelsCommandInput,\n\tRecognizeCelebritiesCommand,\n} from '@aws-sdk/client-rekognition';\nimport {\n\tIdentifyLabelsInput,\n\tIdentifyLabelsOutput,\n\tIdentifySource,\n\tIdentifyEntitiesInput,\n\tIdentifyEntitiesOutput,\n\tisStorageSource,\n\tisFileSource,\n\tisBytesSource,\n\tIdentifyTextInput,\n\tIdentifyTextOutput,\n\tisIdentifyCelebrities,\n\tisIdentifyFromCollection,\n\tIdentifyFromCollection,\n\tFeatureTypes,\n} from '../types';\nimport {\n\tImage,\n\tDocument,\n\tTextDetectionList,\n\tBlockList,\n} from '../types/AWSTypes';\nimport {\n\tTextractClient,\n\tDetectDocumentTextCommand,\n\tDetectDocumentTextCommandInput,\n\tAnalyzeDocumentCommand,\n\tAnalyzeDocumentCommandInput,\n} from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport {\n\tcategorizeRekognitionBlocks,\n\tcategorizeTextractBlocks,\n} from './IdentifyTextUtils';\n\nexport class AmazonAIIdentifyPredictionsProvider extends AbstractIdentifyPredictionsProvider {\n\tprivate rekognitionClient: RekognitionClient;\n\tprivate textractClient: TextractClient;\n\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetProviderName() {\n\t\treturn 'AmazonAIIdentifyPredictionsProvider';\n\t}\n\n\t/**\n\t * Verify user input source and converts it into source object readable by Rekognition and Textract.\n\t * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n\t * @param {IdentifySource} source - User input source that directs to the object user wants\n\t * to identify (storage, file, or bytes).\n\t * @return {Promise<Image>} - Promise resolving to the converted source object.\n\t */\n\tprivate configureSource(source: IdentifySource): Promise<Image> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tif (isStorageSource(source)) {\n\t\t\t\tconst storageConfig = {\n\t\t\t\t\tlevel: source.level,\n\t\t\t\t\tidentityId: source.identityId,\n\t\t\t\t};\n\t\t\t\tStorage.get(source.key, storageConfig)\n\t\t\t\t\t.then((url: string) => {\n\t\t\t\t\t\tconst parser =\n\t\t\t\t\t\t\t/https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n\t\t\t\t\t\tconst parsedURL = url.match(parser);\n\t\t\t\t\t\tif (parsedURL.length < 3) rej('Invalid S3 key was given.');\n\t\t\t\t\t\tres({\n\t\t\t\t\t\t\tS3Object: {\n\t\t\t\t\t\t\t\tBucket: parsedURL[1],\n\t\t\t\t\t\t\t\tName: decodeURIComponent(parsedURL[2]),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t});\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isFileSource(source)) {\n\t\t\t\tblobToArrayBuffer(source.file)\n\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isBytesSource(source)) {\n\t\t\t\tconst bytes = source.bytes;\n\t\t\t\tif (bytes instanceof Blob) {\n\t\t\t\t\tblobToArrayBuffer(bytes)\n\t\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t\t})\n\t\t\t\t\t\t.catch(err => rej(err));\n\t\t\t\t}\n\t\t\t\tif (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n\t\t\t\t\tres({ Bytes: new Uint8Array(bytes) } as Image);\n\t\t\t\t}\n\t\t\t\t// everything else can be directly passed to Rekognition / Textract.\n\t\t\t\tres({ Bytes: bytes } as Image);\n\t\t\t} else {\n\t\t\t\trej('Input source is not configured correctly.');\n\t\t\t}\n\t\t});\n\t}\n\n\t/**\n\t * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n\t * image and converts it into machine-readable text.\n\t * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n\t * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n\t */\n\tprotected async identifyText(\n\t\tinput: IdentifyTextInput\n\t): Promise<IdentifyTextOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyText: {\n\t\t\t\tregion = '',\n\t\t\t\tdefaults: { format: configFormat = 'PLAIN' } = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tthis.textractClient = new TextractClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tlet inputDocument: Document;\n\n\t\ttry {\n\t\t\tinputDocument = await this.configureSource(input.text.source);\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\n\t\t// get default value if format isn't specified in the input.\n\t\tconst format = input.text.format || configFormat;\n\t\tconst featureTypes: FeatureTypes = []; // structures we want to analyze (e.g. [TABLES, FORMS]).\n\t\tif (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n\t\tif (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n\n\t\tif (featureTypes.length === 0) {\n\t\t\t/**\n\t\t\t * Empty featureTypes indicates that we will identify plain text. We will use rekognition (suitable\n\t\t\t * for everyday images but has 50 word limit) first and see if reaches its word limit. If it does, then\n\t\t\t * we call textract and use the data that identify more words.\n\t\t\t */\n\t\t\tconst textractParam: DetectDocumentTextCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t};\n\t\t\tconst rekognitionParam: DetectTextCommandInput = {\n\t\t\t\tImage: inputDocument,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst detectTextCommand = new DetectTextCommand(rekognitionParam);\n\t\t\t\tconst rekognitionData = await this.rekognitionClient.send(\n\t\t\t\t\tdetectTextCommand\n\t\t\t\t);\n\n\t\t\t\tconst rekognitionResponse = categorizeRekognitionBlocks(\n\t\t\t\t\trekognitionData.TextDetections as TextDetectionList\n\t\t\t\t);\n\t\t\t\tif (rekognitionResponse.text.words.length < 50) {\n\t\t\t\t\t// did not hit the word limit, return the data\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\tconst detectDocumentTextCommand = new DetectDocumentTextCommand(\n\t\t\t\t\ttextractParam\n\t\t\t\t);\n\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tdetectDocumentTextCommand\n\t\t\t\t);\n\n\t\t\t\tif (rekognitionData.TextDetections.length > Blocks.length) {\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\tPromise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\tconst param: AnalyzeDocumentCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t\tFeatureTypes: featureTypes,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tanalyzeDocumentCommand\n\t\t\t\t);\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Identify instances of real world entities from an image and if it contains unsafe content.\n\t * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n\t */\n\tprotected async identifyLabels(\n\t\tinput: IdentifyLabelsInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return Promise.reject('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyLabels: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tdefaults: { type = 'LABELS' } = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\t\tregion,\n\t\t\t\tcredentials,\n\t\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t\t});\n\t\t\tlet inputImage: Image;\n\t\t\tawait this.configureSource(input.labels.source)\n\t\t\t\t.then(data => {\n\t\t\t\t\tinputImage = data;\n\t\t\t\t})\n\t\t\t\t.catch(err => {\n\t\t\t\t\treturn Promise.reject(err);\n\t\t\t\t});\n\t\t\tconst param = { Image: inputImage };\n\t\t\tconst servicePromises = [];\n\n\t\t\t// get default argument\n\t\t\tconst entityType = input.labels.type || type;\n\t\t\tif (entityType === 'LABELS' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectLabels(param));\n\t\t\t}\n\t\t\tif (entityType === 'UNSAFE' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectModerationLabels(param));\n\t\t\t}\n\n\t\t\treturn Promise.all(servicePromises)\n\t\t\t\t.then(data => {\n\t\t\t\t\tlet identifyResult: IdentifyLabelsOutput = {};\n\t\t\t\t\t// concatenate resolved promises to a single object\n\t\t\t\t\tdata.forEach(val => {\n\t\t\t\t\t\tidentifyResult = { ...identifyResult, ...val };\n\t\t\t\t\t});\n\t\t\t\t\treturn identifyResult;\n\t\t\t\t})\n\t\t\t\t.catch(err => Promise.reject(err));\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectLabels and organizes the returned data.\n\t * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n\t */\n\tprivate async detectLabels(\n\t\tparam: DetectLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectLabelsCommand = new DetectLabelsCommand(param);\n\t\t\tconst data = await this.rekognitionClient.send(detectLabelsCommand);\n\t\t\tif (!data.Labels) return { labels: null }; // no image was detected\n\t\t\tconst detectLabelData = data.Labels.map(val => {\n\t\t\t\tconst boxes = val.Instances\n\t\t\t\t\t? val.Instances.map(val => makeCamelCase(val.BoundingBox))\n\t\t\t\t\t: undefined;\n\t\t\t\treturn {\n\t\t\t\t\tname: val.Name,\n\t\t\t\t\tboundingBoxes: boxes,\n\t\t\t\t\tmetadata: {\n\t\t\t\t\t\tconfidence: val.Confidence,\n\t\t\t\t\t\tparents: makeCamelCaseArray(val.Parents),\n\t\t\t\t\t},\n\t\t\t\t};\n\t\t\t});\n\t\t\treturn { labels: detectLabelData };\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectModerationLabels and organizes the returned data.\n\t * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n\t */\n\tprivate async detectModerationLabels(\n\t\tparam: DetectModerationLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectModerationLabelsCommand = new DetectModerationLabelsCommand(\n\t\t\t\tparam\n\t\t\t);\n\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\tdetectModerationLabelsCommand\n\t\t\t);\n\t\t\tif (data.ModerationLabels.length !== 0) {\n\t\t\t\treturn { unsafe: 'YES' };\n\t\t\t} else {\n\t\t\t\treturn { unsafe: 'NO' };\n\t\t\t}\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Identify faces within an image that is provided as input, and match faces from a collection\n\t * or identify celebrities.\n\t * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n\t * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n\t */\n\tprotected async identifyEntities(\n\t\tinput: IdentifyEntitiesInput\n\t): Promise<IdentifyEntitiesOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyEntities: {\n\t\t\t\tregion = '',\n\t\t\t\tcelebrityDetectionEnabled = false,\n\t\t\t\tdefaults: {\n\t\t\t\t\tcollectionId: collectionIdConfig = '',\n\t\t\t\t\tmaxEntities: maxFacesConfig = 50,\n\t\t\t\t} = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\t// default arguments\n\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tlet inputImage: Image;\n\t\tawait this.configureSource(input.entities.source)\n\t\t\t.then(data => (inputImage = data))\n\t\t\t.catch(err => {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t});\n\n\t\tconst param = { Attributes: ['ALL'], Image: inputImage };\n\n\t\tif (\n\t\t\tisIdentifyCelebrities(input.entities) &&\n\t\t\tinput.entities.celebrityDetection\n\t\t) {\n\t\t\tif (!celebrityDetectionEnabled) {\n\t\t\t\treturn Promise.reject(\n\t\t\t\t\t'Error: You have to enable celebrity detection first'\n\t\t\t\t);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tconst recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(\n\t\t\t\t\tparam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\trecognizeCelebritiesCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.CelebrityFaces.map(celebrity => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t...makeCamelCase(celebrity, ['Id', 'Name', 'Urls']),\n\t\t\t\t\t\t\tpose: makeCamelCase(celebrity.Face.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else if (\n\t\t\tisIdentifyFromCollection(input.entities) &&\n\t\t\tinput.entities.collection\n\t\t) {\n\t\t\tconst {\n\t\t\t\tcollectionId = collectionIdConfig,\n\t\t\t\tmaxEntities: maxFaces = maxFacesConfig,\n\t\t\t} = input.entities as IdentifyFromCollection;\n\t\t\t// Concatenate additional parameters\n\t\t\tconst updatedParam = {\n\t\t\t\t...param,\n\t\t\t\tCollectionId: collectionId,\n\t\t\t\tMaxFaces: maxFaces,\n\t\t\t};\n\t\t\ttry {\n\t\t\t\tconst searchFacesByImageCommand = new SearchFacesByImageCommand(\n\t\t\t\t\tupdatedParam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\tsearchFacesByImageCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.FaceMatches.map(val => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(val.Face.BoundingBox),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\texternalImageId: this.decodeExternalImageId(\n\t\t\t\t\t\t\t\tval.Face.ExternalImageId\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\tsimilarity: val.Similarity,\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tconst detectFacesCommand = new DetectFacesCommand(param);\n\t\t\t\tconst data = await this.rekognitionClient.send(detectFacesCommand);\n\t\t\t\tconst faces = data.FaceDetails.map(detail => {\n\t\t\t\t\t// face attributes keys we want to extract from Rekognition's response\n\t\t\t\t\tconst attributeKeys = [\n\t\t\t\t\t\t'Smile',\n\t\t\t\t\t\t'Eyeglasses',\n\t\t\t\t\t\t'Sunglasses',\n\t\t\t\t\t\t'Gender',\n\t\t\t\t\t\t'Beard',\n\t\t\t\t\t\t'Mustache',\n\t\t\t\t\t\t'EyesOpen',\n\t\t\t\t\t\t'MouthOpen',\n\t\t\t\t\t];\n\t\t\t\t\tconst faceAttributes = makeCamelCase(detail, attributeKeys);\n\t\t\t\t\tif (detail.Emotions) {\n\t\t\t\t\t\tfaceAttributes['emotions'] = detail.Emotions.map(\n\t\t\t\t\t\t\temotion => emotion.Type\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(detail.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(detail.Landmarks),\n\t\t\t\t\t\tageRange: makeCamelCase(detail.AgeRange),\n\t\t\t\t\t\tattributes: faceAttributes,\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\tconfidence: detail.Confidence,\n\t\t\t\t\t\t\tpose: makeCamelCase(detail.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate decodeExternalImageId(externalImageId: string): string {\n\t\treturn ('' + externalImageId).replace(/::/g, '/');\n\t}\n}\n"]},"metadata":{},"sourceType":"module"}